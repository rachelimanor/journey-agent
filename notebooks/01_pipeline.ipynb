{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8647ef3c-e0e6-4884-9a32-47fabd4cfce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import openai, pandas as pd, requests, bs4, readability, lxml, praw, os\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96340db7-8cdb-479e-934c-4f2ffff74091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI: True\n",
      "SERPAPI: True\n",
      "REDDIT: True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()\n",
    "import os\n",
    "print(\"OPENAI:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"SERPAPI:\", bool(os.getenv(\"SERPAPI_API_KEY\")))\n",
    "print(\"REDDIT:\", all([os.getenv(\"REDDIT_CLIENT_ID\"), os.getenv(\"REDDIT_CLIENT_SECRET\"), os.getenv(\"REDDIT_USER_AGENT\")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865247fd-9f16-424d-98d9-745c1ebecf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage 0: Planner — propose subreddits & queries from a prior markdown report ---\n",
    "\n",
    "import os, re, json, pathlib\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "INSIGHTS_FILENAME = \"insights_20251025_1652.md\"   # <- change per run as needed\n",
    "INSIGHTS_PATH = pathlib.Path(\"../data/exports\") / INSIGHTS_FILENAME\n",
    "\n",
    "assert INSIGHTS_PATH.exists(), f\"Missing file: {INSIGHTS_PATH}\"\n",
    "ctx_md = INSIGHTS_PATH.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# ----- Structured outputs schema: object with arrays -----\n",
    "RESULT_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"subreddits\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\", \"minLength\": 3, \"maxLength\": 32},\n",
    "            \"maxItems\": 10\n",
    "        },\n",
    "        \"queries\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\", \"minLength\": 3, \"maxLength\": 200},\n",
    "            \"maxItems\": 10\n",
    "        },\n",
    "        # optional notes/rationale (not used downstream but handy for debugging)\n",
    "        \"notes\": {\"type\": [\"string\", \"null\"]}\n",
    "    },\n",
    "    \"required\": [\"subreddits\", \"queries\"]\n",
    "}\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You are a senior UX researcher and search strategist. \"\n",
    "    \"Given a research summary + instructions, output up to 10 relevant Reddit subreddits \"\n",
    "    \"and up to 10 focused search queries to discover pain points for private-party used-car transactions.\"\n",
    ")\n",
    "\n",
    "USER = f\"\"\"\n",
    "CONTEXT (Markdown from prior run):\n",
    "---\n",
    "{ctx_md}\n",
    "---\n",
    "\n",
    "TASK:\n",
    "- Generate up to 10 subreddits that are most likely to contain firsthand experiences, how-tos, and pitfalls relevant to private-party used-car buying/selling in the U.S.\n",
    "- Generate up to 10 search queries tuned for Reddit search, covering payments/scams, title/lien, inspections/OBD, negotiating, financing, insurance, paperwork, scheduling/meeting, post-purchase issues.\n",
    "- Prefer **practical, specific** queries that surface stories (e.g., \"private party title transfer lien release\", \"cashier's check scam private sale\", \"mobile mechanic OBD pre-purchase\").\n",
    "- Exclude dealership-only communities or irrelevant car culture subs unless they have frequent private-sale threads.\n",
    "\n",
    "OUTPUT:\n",
    "Return a JSON object with:\n",
    "- \"subreddits\": string[]\n",
    "- \"queries\": string[]\n",
    "- \"notes\": optional rationale\n",
    "\n",
    "Guidelines:\n",
    "- Do NOT include the 'r/' prefix.\n",
    "- Avoid duplicates and overly-broad terms like just \"used car\".\n",
    "- Favor U.S. context unless the summary indicates otherwise.\n",
    "\"\"\"\n",
    "\n",
    "chat = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.2,\n",
    "    messages=[{\"role\":\"system\",\"content\": SYSTEM},\n",
    "              {\"role\":\"user\",\"content\": USER}],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\"name\":\"PlanSpec\",\"schema\":RESULT_SCHEMA,\"strict\":True}\n",
    "    }\n",
    ")\n",
    "\n",
    "import json as _json\n",
    "plan = _json.loads(chat.choices[0].message.content)\n",
    "\n",
    "# ----- Normalize / validate -----\n",
    "def norm_sub(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"^(?:/)?r/\", \"\", s, flags=re.I)  # drop r/ or /r/\n",
    "    s = re.sub(r\"[^A-Za-z0-9_]\", \"\", s)          # keep reddit-safe chars\n",
    "    return s\n",
    "\n",
    "SUGGESTED_SUBREDDITS = []\n",
    "seen = set()\n",
    "for s in plan.get(\"subreddits\", []):\n",
    "    n = norm_sub(s)\n",
    "    if 3 <= len(n) <= 32 and n.lower() not in seen:\n",
    "        SUGGESTED_SUBREDDITS.append(n)\n",
    "        seen.add(n.lower())\n",
    "\n",
    "# trim queries, dedupe\n",
    "SUGGESTED_QUERIES = []\n",
    "seenq = set()\n",
    "for q in plan.get(\"queries\", []):\n",
    "    qn = \" \".join(q.split())\n",
    "    if 3 <= len(qn) <= 200 and qn.lower() not in seenq:\n",
    "        SUGGESTED_QUERIES.append(qn)\n",
    "        seenq.add(qn.lower())\n",
    "\n",
    "print(\"Planner → suggested subreddits:\", SUGGESTED_SUBREDDITS)\n",
    "print(\"Planner → suggested queries:\", SUGGESTED_QUERIES)\n",
    "if plan.get(\"notes\"):\n",
    "    print(\"\\nNotes:\\n\", plan[\"notes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2413e52c-eff9-4aec-9c47-ce5b15f0c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 20251025_1652\n"
     ]
    }
   ],
   "source": [
    "# Configuation\n",
    "\n",
    "# --- config ---\n",
    "TOPIC = \"Private-party used-car buying in SF Bay Area\"\n",
    "SUBREDDITS = [\"UsedCars\", \"MechanicAdvice\", \"WhatCarShouldIBuy\", \"cars\", \"Scams\", \"AskCarsales\"]\n",
    "QUERY_STRINGS = [\n",
    "    'Buying a used car',\n",
    "    'private party payment cashier check',\n",
    "    'private party title lien transfer',\n",
    "    'private party escrow payment',\n",
    "    'inspection OBD checklist private sale',\n",
    "    'wire vs cash private sale',\n",
    "]\n",
    "\n",
    "\n",
    "RECENCY_MONTHS = 24\n",
    "SINCE_DAYS = RECENCY_MONTHS * 30  # Stage 1 uses days\n",
    "THREADS_PER_QUERY = 4   # keep small for first run\n",
    "TOP_COMMENTS = 4\n",
    "\n",
    "import os, json, time, math, datetime as dt, re, pathlib # re = pyton regex. pathlib = an easy way to manage env vars.\n",
    "import praw as praw # Reddit API\n",
    "from openai import OpenAI # OpenAI API\n",
    "\n",
    "# loads the environment vars from .env\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "\n",
    "# Creates an env var for the outputs, and creates a data/exports dir that corresponds with the env var\n",
    "EXPORTS = pathlib.Path(\"../data/exports\"); EXPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "RUN_ID = dt.datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
    "print(\"Run:\", RUN_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068c1bc-ac2a-4faf-bceb-8e65380a4e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - new\n",
    "\n",
    "# --- topic ---\n",
    "TOPIC = \"Private-party used-car buying in the US\"\n",
    "\n",
    "# --- use suggestions from Stage 0 if present; else fall back ---\n",
    "DEFAULT_SUBS = [\"UsedCars\", \"MechanicAdvice\", \"WhatCarShouldIBuy\", \"cars\", \"Scams\", \"AskCarsales\"]\n",
    "DEFAULT_QUERIES = [\n",
    "    \"Buying a used car\",\n",
    "    \"private party payment cashier check\",\n",
    "    \"private party title lien transfer\",\n",
    "    \"private party escrow payment\",\n",
    "    \"inspection OBD checklist private sale\",\n",
    "    \"wire vs cash private sale\",\n",
    "]\n",
    "\n",
    "SUBREDDITS = SUGGESTED_SUBREDDITS if 'SUGGESTED_SUBREDDITS' in globals() and SUGGESTED_SUBREDDITS else DEFAULT_SUBS\n",
    "QUERY_STRINGS = SUGGESTED_QUERIES if 'SUGGESTED_QUERIES' in globals() and SUGGESTED_QUERIES else DEFAULT_QUERIES\n",
    "\n",
    "# knobs\n",
    "RECENCY_MONTHS = 24\n",
    "SINCE_DAYS = RECENCY_MONTHS * 30\n",
    "THREADS_PER_QUERY = 4\n",
    "TOP_COMMENTS = 4\n",
    "\n",
    "import os, json, time, math, datetime as dt, re, pathlib # re = pyton regex. pathlib = an easy way to manage env vars.\n",
    "import praw as praw # Reddit API\n",
    "from openai import OpenAI # OpenAI API\n",
    "from dotenv import load_dotenv; load_dotenv() # loads the environment vars from .env\n",
    "\n",
    "\n",
    "# Creates an env var for the outputs, and creates a data/exports dir that corresponds with the env var\n",
    "EXPORTS = pathlib.Path(\"../data/exports\"); EXPORTS.mkdir(parents=True, exist_ok=True)\n",
    "RUN_ID = dt.datetime.utcnow().strftime(\"%Y%m%d_%H%M\")\n",
    "print(\"Run:\", RUN_ID)\n",
    "print(\"Using subreddits:\", SUBREDDITS)\n",
    "print(\"Using queries:\", QUERY_STRINGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1955481-706a-461d-8751-54d41c5ec1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads found (after recency + dedupe): 80\n",
      "- r/UsedCars | 2025-10-11T17:56:53Z | how do you buy a used car?…\n",
      "- r/UsedCars | 2025-08-01T20:49:40Z | Is buying a used car still the way to go?…\n",
      "- r/UsedCars | 2025-08-07T16:51:57Z | How do people even buy used cars.…\n",
      "- r/UsedCars | 2025-07-25T15:23:52Z | I sold a classic car to this guy (private sale) and now he's saying I misrepresented the car and he's giving me the opportunity to buy the car back.…\n",
      "- r/MechanicAdvice | 2025-07-17T05:27:12Z | Is there any used car worth buying with high miles?…\n"
     ]
    }
   ],
   "source": [
    "# --- Stage 1: Researcher (Reddit via PRAW search) ---\n",
    "\n",
    "# connect to Reddit (uses your .env values)\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "    user_agent=os.getenv(\"REDDIT_USER_AGENT\"),\n",
    ")\n",
    "\n",
    "reddit.read_only = True\n",
    "\n",
    "# simple call: fetch one hot post from r/UsedCars\n",
    "#sub = reddit.subreddit(\"UsedCars\")\n",
    "#post = next(sub.hot(limit=1))\n",
    "#print(\"OK:\", post.title[:80])\n",
    "\n",
    "\n",
    "def search_threads(query, subreddits, limit_per_sub, since_days):\n",
    "    \"\"\" Search Reddit for `query` across `subreddits`, keeping posts newer than `since_days`.\n",
    "\n",
    "    Args:\n",
    "        query: Search string (e.g., \"private party escrow\").\n",
    "        subreddits: List like [\"UsedCars\", \"MechanicAdvice\"].\n",
    "        limit_per_sub: Max results per subreddit (before filtering).\n",
    "        since_days: Recency window; older posts are dropped.\n",
    "\n",
    "    Returns:\n",
    "        A de-duplicated list of thread dicts with id, title, permalink, timestamps, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    after_ts = time.time() - since_days * 24 * 3600\n",
    "    found = []\n",
    "    \n",
    "    for sub in subreddits:\n",
    "        sr = reddit.subreddit(sub)\n",
    "        # Reddit search (relevance) with a per-subreddit cap\n",
    "        for submission in sr.search(query, sort=\"relevance\", limit=limit_per_sub):\n",
    "            if submission.created_utc < after_ts:\n",
    "                continue\n",
    "            found.append({\n",
    "                \"id\": submission.id,\n",
    "                \"subreddit\": str(sub),\n",
    "                \"title\": submission.title,\n",
    "                \"permalink\": \"https://www.reddit.com\" + submission.permalink,\n",
    "                \"created_utc\": submission.created_utc,\n",
    "                \"created_iso\": dt.datetime.utcfromtimestamp(submission.created_utc).isoformat() + \"Z\",\n",
    "                \"is_self\": submission.is_self,\n",
    "                \"url\": submission.url,\n",
    "                \"query\": query,\n",
    "            })\n",
    "    # de-dupe by submission id\n",
    "    seen = set()\n",
    "    dedup = []\n",
    "    for r in found:\n",
    "        if r[\"id\"] in seen:\n",
    "            continue\n",
    "        seen.add(r[\"id\"])\n",
    "        dedup.append(r)\n",
    "    return dedup\n",
    "\n",
    "\n",
    "# run searches over your configured queries/subreddits\n",
    "all_threads = []\n",
    "for q in QUERY_STRINGS:\n",
    "    all_threads += search_threads(\n",
    "        query=q, \n",
    "        subreddits=SUBREDDITS, \n",
    "        limit_per_sub=THREADS_PER_QUERY, \n",
    "        since_days=SINCE_DAYS\n",
    "    )\n",
    "\n",
    "# global de-dup (across queries)\n",
    "seen_ids, threads = set(), []\n",
    "for r in all_threads:\n",
    "    if r[\"id\"] in seen_ids: \n",
    "        continue\n",
    "    seen_ids.add(r[\"id\"]); threads.append(r)\n",
    "\n",
    "print(f\"Threads found (after recency + dedupe): {len(threads)}\")\n",
    "# quick peek\n",
    "for t in threads[:5]:\n",
    "    print(f\"- r/{t['subreddit']} | {t['created_iso']} | {t['title'][:200]}…\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c2cab9c-2cd2-4116-bb93-0adb1fe0d401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/exports/bundles_20251025_1652.json'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Stage 2: Crawler — expand each thread with post + top comments ---\n",
    "\n",
    "def fetch_thread(submission_id: str, top_n: int = TOP_COMMENTS) -> dict:\n",
    "    sub = reddit.submission(id=submission_id)\n",
    "    sub.comment_sort = \"top\"\n",
    "    # flatten \"More comments…\" so we get real comments\n",
    "    sub.comments.replace_more(limit=0)\n",
    "\n",
    "    comments = []\n",
    "    for c in sub.comments[:top_n]:\n",
    "        comments.append({\n",
    "            \"author\": str(c.author) if c.author else \"deleted\",\n",
    "            \"body\": c.body,\n",
    "            \"permalink\": f\"https://www.reddit.com{c.permalink}\",\n",
    "            \"created_utc\": c.created_utc,\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"thread_id\": sub.id,\n",
    "        \"subreddit\": str(sub.subreddit),\n",
    "        \"thread_title\": sub.title,\n",
    "        \"selftext\": sub.selftext or \"\",\n",
    "        \"permalink\": f\"https://www.reddit.com{sub.permalink}\",\n",
    "        \"created_utc\": sub.created_utc,\n",
    "        \"comments\": comments,\n",
    "    }\n",
    "\n",
    "# run crawler over the threads we just found\n",
    "bundles = []\n",
    "for t in threads:\n",
    "    try:\n",
    "        bundles.append(fetch_thread(t[\"id\"], top_n=TOP_COMMENTS))\n",
    "    except Exception as e:\n",
    "        print(\"crawl error:\", t[\"id\"], e)\n",
    "\n",
    "\n",
    "def preview_bundles(bundles, max_title=100, max_comment=140):\n",
    "    for idx, b in enumerate(bundles, 1):\n",
    "        print(f\"\\n[{idx}] r/{b['subreddit']} | {b['thread_title'][:max_title]}\")\n",
    "        print(f\"    Thread: {b['permalink']}\")\n",
    "        for i, c in enumerate(b[\"comments\"], 1):\n",
    "            body = \" \".join(c[\"body\"].split())  # collapse whitespace/newlines\n",
    "            excerpt = (body[:max_comment] + \"…\") if len(body) > max_comment else body\n",
    "            print(f\"    {i:02d}. {excerpt}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "#preview_bundles(bundles)\n",
    "\n",
    "# Print into a json file\n",
    "out_path = EXPORTS / f\"bundles_{RUN_ID}.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(bundles, f, ensure_ascii=False, indent=2)\n",
    "str(out_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36c1bab8-8874-4ade-b4c8-66e14dcbcca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bundles before LLM: 80 → after pre-dedupe: 80\n"
     ]
    }
   ],
   "source": [
    "# --- Stage 3.1 Pre-LLM dedupe of bundles (saves tokens) ---\n",
    "\n",
    "import hashlib, re\n",
    "\n",
    "def sig_for_bundle(b):\n",
    "    \"\"\"Signature of thread content for dedupe: title + selftext + top comment bodies (normalized).\"\"\"\n",
    "    text_parts = [b.get(\"thread_title\",\"\"), b.get(\"selftext\",\"\")]\n",
    "    text_parts += [c.get(\"body\",\"\") for c in b.get(\"comments\", [])]\n",
    "    raw = \" \".join(text_parts).lower()\n",
    "    raw = re.sub(r\"\\s+\", \" \", raw).strip()\n",
    "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "seen_sig = set()\n",
    "bundles_dedup = []\n",
    "for b in bundles:\n",
    "    sig = sig_for_bundle(b)\n",
    "    if sig in seen_sig: \n",
    "        continue\n",
    "    seen_sig.add(sig)\n",
    "    bundles_dedup.append(b)\n",
    "\n",
    "print(f\"Bundles before LLM: {len(bundles)} → after pre-dedupe: {len(bundles_dedup)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa771f0f-de79-4806-876d-9efc5a8c9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage 3: Extractor — LLM → structured rows ---\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "SCHEMA = {\n",
    " \"persona\": \"buyer|seller|unknown\",\n",
    " \"stage\": \"initial research | choosing the right car | inspection and car condition | scheduling and meeting the other party | negotiation and pricing | payment | paperwork | financing | insurance | post purchase\",\n",
    " \"action\": \"what they did\",\n",
    " \"feeling\": \"how they felt\",\n",
    " \"pain\": \"risk/annoyance/issue (null if none)\",\n",
    " \"workaround\": \"what they tried (null if none)\",\n",
    " \"opportunity\": \"What value we could create to help (null if none)\",\n",
    " \"verbatim_quote\": \"exact sentence from source\",\n",
    " \"source_url\": \"https://...\",\n",
    " \"permalink\": \"https://...#comment-id (or thread permalink)\",\n",
    " \"source_type\": \"reddit\",\n",
    " \"thread_title\": \"...\",\n",
    " \"posted_at\": \"ISO8601 or null\",\n",
    " \"location_city\": \"city name or null\",\n",
    " \"location_state\": \"US state/region or null\",\n",
    " \"location_hint\": \"free text if mentioned (dealer/DMV names, banks, neighborhoods) or null\",\n",
    " \"potential_competitor\": \"name/url of service used or mentioned as a solution, else null\",\n",
    " \"stage_confidence\": 0.0,\n",
    " \"persona_confidence\": 0.0\n",
    "}\n",
    "\n",
    "\n",
    "EXTRACT_GUIDE = \"\"\"\n",
    "Act as a UX researcher analyzing PRIVATE-PARTY used-car transactions (person buys from a private seller, not a dealer).\n",
    "You will read SOURCE TEXT (thread title/body and top comments) and output ONLY a JSON array of objects following the SCHEMA exactly.\n",
    "\n",
    "GOAL\n",
    "- Detect concrete PAIN POINTS expressed or clearly implied in the text.\n",
    "- For each distinct pain point (or strong observation with clear action/feeling), emit ONE object.\n",
    "- If there is no concrete pain/observation, return [].\n",
    "\n",
    "STRICT RULES\n",
    "1) JSON ONLY. No prose, no markdown, no trailing commas.\n",
    "2) Use the provided enum values EXACTLY:\n",
    "   - persona: buyer|seller|unknown\n",
    "   - stage: one of\n",
    "     \"initial research\" | \"choosing the right car\" | \"inspection and car condition\" |\n",
    "     \"scheduling and meeting the other party\" | \"negotiation and pricing\" | \"payment\" |\n",
    "     \"paperwork\" | \"financing\" | \"insurance\" | \"post purchase\"\n",
    "3) Evidence:\n",
    "   - Include at least ONE verbatim sentence from the SOURCE TEXT as \"verbatim_quote\".\n",
    "     • Do not paraphrase in that field.\n",
    "   - Use the comment's permalink if quoting a comment; otherwise the thread permalink.\n",
    "4) Fields:\n",
    "   - Keep \"action\", \"feeling\", \"pain\", \"workaround\", \"opportunity\" concise and pragmatic.\n",
    "   - If a field isn’t present in the text, set it to null (do NOT invent).\n",
    "   - Extract location if present:\n",
    "     • location_city and location_state when clearly mentioned (e.g., \"San Jose, CA\"), else null\n",
    "     • location_hint for looser clues (DMV names, banks, neighborhoods), else null\n",
    "   - potential_competitor: name and/or URL of any service/app used/mentioned to solve the issue (escrow, inspection, payments, insurance, financing), else null\n",
    "5) Confidence:\n",
    "   - Set stage_confidence and persona_confidence between 0.0 and 1.0 based on textual clarity.\n",
    "6) Scope control:\n",
    "   - Only include content about private-party used-car buying/selling. Ignore dealership stories unless directly relevant to a private-party comparison.\n",
    "\n",
    "OUTPUT FORMAT\n",
    "- Return a JSON object with a single key \"rows\".\n",
    "- \"rows\" must be a JSON array of objects matching the schema.\n",
    "- If there are no qualifying observations, return {\"rows\": []}.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# --- Structured Outputs schema (object with rows array) ---\n",
    "ROW_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"persona\": {\"type\":\"string\",\"enum\":[\"buyer\",\"seller\",\"unknown\"]},\n",
    "        \"stage\": {\"type\":\"string\",\"enum\":[\n",
    "            \"initial research\",\"choosing the right car\",\"inspection and car condition\",\n",
    "            \"scheduling and meeting the other party\",\"negotiation and pricing\",\n",
    "            \"payment\",\"paperwork\",\"financing\",\"insurance\",\"post purchase\"\n",
    "        ]},\n",
    "        \"action\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"feeling\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"pain\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"workaround\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"opportunity\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"verbatim_quote\": {\"type\":\"string\"},\n",
    "        \"source_url\": {\"type\":\"string\"},\n",
    "        \"permalink\": {\"type\":\"string\"},\n",
    "        \"source_type\": {\"type\":\"string\",\"const\":\"reddit\"},\n",
    "        \"thread_title\": {\"type\":\"string\"},\n",
    "        \"posted_at\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"location_city\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"location_state\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"location_hint\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"potential_competitor\": {\"type\":[\"string\",\"null\"]},\n",
    "        \"stage_confidence\": {\"type\":\"number\"},\n",
    "        \"persona_confidence\": {\"type\":\"number\"}\n",
    "    },\n",
    "    \"required\": [\n",
    "        \"persona\",\"stage\",\"action\",\"feeling\",\"pain\",\"workaround\",\"opportunity\",\n",
    "        \"verbatim_quote\",\"source_url\",\"permalink\",\"source_type\",\"thread_title\",\n",
    "        \"posted_at\",\"location_city\",\"location_state\",\"location_hint\",\n",
    "        \"potential_competitor\",\"stage_confidence\",\"persona_confidence\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "RESULT_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"rows\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": ROW_SCHEMA\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"rows\"]\n",
    "}\n",
    "\n",
    "#ARRAY_SCHEMA = {\"type\":\"array\",\"items\": ROW_SCHEMA}\n",
    "\n",
    "\n",
    "def extract_from_bundle(b):\n",
    "    parts = [f\"THREAD: {b['thread_title']}\", b.get(\"selftext\",\"\")]\n",
    "    for c in b.get(\"comments\", []):\n",
    "        parts.append(f\"COMMENT ({c['permalink']}): {c['body']}\")\n",
    "    text = \"\\n\\n\".join(parts)[:20000]\n",
    "\n",
    "    chat = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",  # or \"o3-mini\"\n",
    "        temperature=0.15,\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":\"You extract structured observations for private-party used-car journeys.\"},\n",
    "            {\"role\":\"user\",\"content\": json.dumps({\n",
    "                \"schema\": SCHEMA,\n",
    "                \"thread_permalink\": b[\"permalink\"],\n",
    "                \"text\": text\n",
    "            })},\n",
    "            {\"role\":\"user\",\"content\": EXTRACT_GUIDE}\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\"name\":\"RowObject\",\"schema\": RESULT_SCHEMA, \"strict\": True}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    import json as _json\n",
    "    try:\n",
    "        obj = _json.loads(chat.choices[0].message.content)  # object with \"rows\"\n",
    "        arr = obj.get(\"rows\", [])\n",
    "    except Exception as e:\n",
    "        print(\"parse error:\", e)\n",
    "        return []\n",
    "\n",
    "    # bound per-thread, optional\n",
    "    MAX_ROWS_PER_THREAD = 6\n",
    "    arr = arr[:MAX_ROWS_PER_THREAD]\n",
    "\n",
    "    # normalize/stamp\n",
    "    for r in arr:\n",
    "        r.setdefault(\"source_url\", b[\"permalink\"])\n",
    "        r.setdefault(\"thread_title\", b[\"thread_title\"])\n",
    "        r.setdefault(\"source_type\", \"reddit\")\n",
    "        if not r.get(\"permalink\"): r[\"permalink\"] = b[\"permalink\"]\n",
    "        for k in (\"stage_confidence\",\"persona_confidence\"):\n",
    "            try:\n",
    "                v = float(r.get(k, 0.0)); r[k] = max(0.0, min(1.0, v))\n",
    "            except Exception:\n",
    "                r[k] = 0.0\n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "439bc9d6-9c23-49a8-b360-7f62c2ec87b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07fd0287f194564886a375cd8dfdb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LLM extract & cache:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached to: ../data/exports/raw_20251025_1652\n"
     ]
    }
   ],
   "source": [
    "# Stage 3.3\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "RAW_DIR = EXPORTS / f\"raw_{RUN_ID}\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def generate_and_cache(b, idx):\n",
    "    target = RAW_DIR / f\"{idx:04d}.json\"\n",
    "    if target.exists():\n",
    "        return\n",
    "    arr = extract_from_bundle(b)          # LLM call ONCE\n",
    "    payload = {\"thread_permalink\": b[\"permalink\"], \"thread_title\": b[\"thread_title\"], \"rows\": arr}\n",
    "    with open(target, \"w\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "for i, b in enumerate(tqdm(bundles_dedup, desc=\"LLM extract & cache\"), start=1):\n",
    "    generate_and_cache(b, i)\n",
    "\n",
    "print(\"Cached to:\", RAW_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef86219f-dfea-465d-8654-207c09169d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows from cache: 160\n"
     ]
    }
   ],
   "source": [
    "# Stage 3B - Load cached rows\n",
    "import json, glob\n",
    "\n",
    "rows = []\n",
    "files = sorted(glob.glob(str(RAW_DIR / \"*.json\")))\n",
    "for fp in files:\n",
    "    with open(fp, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        rows += data.get(\"rows\", [])\n",
    "\n",
    "print(\"Loaded rows from cache:\", len(rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4f38f4b-ec44-4829-ae0f-47dd51420119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows → raw: 160 | clean: 160 | deduped: 160 | final: 160\n"
     ]
    }
   ],
   "source": [
    "# --- Stage 4: Normalize / Dedupe / Filter ---\n",
    "\n",
    "# It drops query strings (?utm=…) and fragments (#comment-123) so two URLs that are the same page compare equal.\n",
    "# Examples:\n",
    "# https://site.com/page?utm_source=news#section → https://site.com/page\n",
    "# https://reddit.com/r/UsedCars/comments/abc123/?sort=top → https://reddit.com/r/UsedCars/comments/abc123/\n",
    "def canon_url(u: str) -> str:\n",
    "    if not u: return \"\"\n",
    "        \n",
    "    # substitute ? or # and everything that comes after it with  \"\". Strip removes any leading or trailing spaces from a string\n",
    "    return re.sub(r\"[?#].*$\", \"\", u.strip()) \n",
    "\n",
    "# Input\n",
    "# r: dict — one extracted row from the LLM (a Python dict). It should have numeric fields:\n",
    "#     stage_confidence\n",
    "#     persona_confidence\n",
    "#\n",
    "# min_conf: float = 0.5 — the threshold both confidences must meet or exceed (defaults to 0.5).\n",
    "#\n",
    "# Output\n",
    "# bool — True if both confidences are ≥ min_conf; otherwise False.\n",
    "#\n",
    "# Algorithm (one-liner, expanded)\n",
    "# Look up stage_confidence and persona_confidence in r with .get(...).\n",
    "# If a key is missing, use 0 as a default.\n",
    "# Cast each value to float (handles strings like \"0.72\" or None safely—non-numeric strings would raise).\n",
    "# Compare both to min_conf.\n",
    "# Return True only if both comparisons pass (logical AND).\n",
    "def ok_conf(r: dict, min_conf: float = 0.5) -> bool:\n",
    "    return (\n",
    "        float(r.get(\"stage_confidence\", 0)) >= min_conf and\n",
    "        float(r.get(\"persona_confidence\", 0)) >= min_conf\n",
    "    )\n",
    "\n",
    "# Purpose\n",
    "# Gate rows by recency: keep items whose timestamp is within the last months (default RECENCY_MONTHS). It’s a soft filter—if there’s no usable date, \n",
    "# it keeps the row rather than throwing it away.\n",
    "#\n",
    "# Signature (inputs → output)\n",
    "# Input\n",
    "# iso: str — a timestamp string in (roughly) ISO-8601 (e.g., \"2024-07-15T12:34:56Z\" or \"2024-07-15T12:34:56\").\n",
    "# months: int = 24 — how many months back to allow (approximate, using 30 days per month).\n",
    "#\n",
    "# Output\n",
    "# bool — True if the row should be kept, False if it’s too old.\n",
    "def within_months(iso: str, months: int = RECENCY_MONTHS) -> bool:\n",
    "    if not iso:\n",
    "        return True\n",
    "    try:\n",
    "        d = dt.datetime.fromisoformat(iso.replace(\"Z\",\"\"))\n",
    "        cutoff = dt.datetime.utcnow() - dt.timedelta(days=months*30)\n",
    "        return d >= cutoff\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "# Python list comprehensions\n",
    "# [new_item   for item in iterable   if condition]\n",
    "# Read it left→right: “Put new_item into a list for each item in iterable if condition.”\n",
    "\n",
    "# Breakdown:\n",
    "# r for r in rows → iterate all extracted row dicts.\n",
    "# r.get(\"verbatim_quote\") → fetches the value (or None if missing). In an if, this is truthy only if it exists and isn’t empty (e.g., not \"\").\n",
    "# and r.get(\"source_url\") → also require a non-empty source_url.\n",
    "# The comprehension builds a new list with only rows that satisfy both conditions.\n",
    "#\n",
    "# Why:\n",
    "# We require a real, verbatim quote (evidence) and a URL to verify it. Rows missing either are dropped before dedupe/QA.\n",
    "\n",
    "# 1) must-haves\n",
    "rows_clean = [r for r in rows if r.get(\"verbatim_quote\") and r.get(\"source_url\")]\n",
    "\n",
    "# What it does\n",
    "# Goal: keep only the first occurrence of a row with the same quote + URL.\n",
    "# seen (set): fast membership check of keys we’ve already kept.\n",
    "# key: a tuple of\n",
    "# the quote text (trimmed), and\n",
    "# a canonicalized URL (permalink if present, else source_url, with query/fragment stripped by canon_url).\n",
    "# If the key was seen before → skip; otherwise record it and append the row to deduped.\n",
    "\n",
    "# 2) de-dupe by (verbatim_quote, permalink-or-source_url)\n",
    "seen = set(); deduped = []\n",
    "for r in rows_clean:\n",
    "    key = (r[\"verbatim_quote\"].strip(), canon_url(r.get(\"permalink\") or r.get(\"source_url\")))\n",
    "    if key in seen: \n",
    "        continue\n",
    "    seen.add(key); deduped.append(r)\n",
    "\n",
    "# 3) confidence gate\n",
    "filtered = [r for r in deduped if ok_conf(r, min_conf=0.5)]\n",
    "\n",
    "# 4) optional recency filter if posted_at present\n",
    "filtered = [r for r in filtered if within_months(r.get(\"posted_at\",\"\"), months=24)]\n",
    "\n",
    "print(f\"Rows → raw: {len(rows)} | clean: {len(rows_clean)} | deduped: {len(deduped)} | final: {len(filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c687c2c-a2e5-4831-9691-0e76b6d98a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona</th>\n",
       "      <th>stage</th>\n",
       "      <th>source_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buyer</td>\n",
       "      <td>choosing the right car</td>\n",
       "      <td>reddit</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buyer</td>\n",
       "      <td>financing</td>\n",
       "      <td>reddit</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buyer</td>\n",
       "      <td>initial research</td>\n",
       "      <td>reddit</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buyer</td>\n",
       "      <td>inspection and car condition</td>\n",
       "      <td>reddit</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buyer</td>\n",
       "      <td>insurance</td>\n",
       "      <td>reddit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>buyer</td>\n",
       "      <td>negotiation and pricing</td>\n",
       "      <td>reddit</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>buyer</td>\n",
       "      <td>paperwork</td>\n",
       "      <td>reddit</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>buyer</td>\n",
       "      <td>payment</td>\n",
       "      <td>reddit</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>buyer</td>\n",
       "      <td>post purchase</td>\n",
       "      <td>reddit</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buyer</td>\n",
       "      <td>scheduling and meeting the other party</td>\n",
       "      <td>reddit</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seller</td>\n",
       "      <td>negotiation and pricing</td>\n",
       "      <td>reddit</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>seller</td>\n",
       "      <td>paperwork</td>\n",
       "      <td>reddit</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>seller</td>\n",
       "      <td>payment</td>\n",
       "      <td>reddit</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>seller</td>\n",
       "      <td>post purchase</td>\n",
       "      <td>reddit</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>seller</td>\n",
       "      <td>scheduling and meeting the other party</td>\n",
       "      <td>reddit</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>unknown</td>\n",
       "      <td>paperwork</td>\n",
       "      <td>reddit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    persona                                   stage source_type  count\n",
       "0     buyer                  choosing the right car      reddit      6\n",
       "1     buyer                               financing      reddit      9\n",
       "2     buyer                        initial research      reddit     14\n",
       "3     buyer            inspection and car condition      reddit     30\n",
       "4     buyer                               insurance      reddit      2\n",
       "5     buyer                 negotiation and pricing      reddit      7\n",
       "6     buyer                               paperwork      reddit     19\n",
       "7     buyer                                 payment      reddit     19\n",
       "8     buyer                           post purchase      reddit     16\n",
       "9     buyer  scheduling and meeting the other party      reddit      5\n",
       "10   seller                 negotiation and pricing      reddit      5\n",
       "11   seller                               paperwork      reddit      3\n",
       "12   seller                                 payment      reddit     16\n",
       "13   seller                           post purchase      reddit      3\n",
       "14   seller  scheduling and meeting the other party      reddit      5\n",
       "15  unknown                               paperwork      reddit      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>payment</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inspection and car condition</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paperwork</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post purchase</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>initial research</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negotiation and pricing</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scheduling and meeting the other party</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>financing</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>choosing the right car</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>insurance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    stage  count\n",
       "0                                 payment     35\n",
       "1            inspection and car condition     30\n",
       "2                               paperwork     23\n",
       "3                           post purchase     19\n",
       "4                        initial research     14\n",
       "5                 negotiation and pricing     12\n",
       "6  scheduling and meeting the other party     10\n",
       "7                               financing      9\n",
       "8                  choosing the right car      6\n",
       "9                               insurance      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona</th>\n",
       "      <th>stage</th>\n",
       "      <th>verbatim_quote</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>permalink</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>location_city</th>\n",
       "      <th>location_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buyer</td>\n",
       "      <td>initial research</td>\n",
       "      <td>Well, if you\u0019ve never bought one or been to a dealership, do not ever go in person. They\u001d",
       " see you coming a mile away and get you to buy something you don\u001bt ...</td>\n",
       "      <td>Provide trustworthy third party tools to handle dealer interactions and avoid pressure tactics</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nj4df06/</td>\n",
       "      <td>how do you buy a used car?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buyer</td>\n",
       "      <td>choosing the right car</td>\n",
       "      <td>Vehicle history is important. Was it a rental? How many owners, any accidents, and how was the maintenance? Most dealerships will offer a car fax history re...</td>\n",
       "      <td>Offer comprehensive vehicle history and condition reports; facilitate trusted inspections</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nizb6pt/</td>\n",
       "      <td>how do you buy a used car?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buyer</td>\n",
       "      <td>inspection and car condition</td>\n",
       "      <td>If you made it this far and want to take the extra step, especially if you didnt understand all of that. Drive it to a reputable shop across town. Pay for a...</td>\n",
       "      <td>Provide easy access to trusted inspection services and clear condition summaries</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nizb6pt/</td>\n",
       "      <td>how do you buy a used car?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buyer</td>\n",
       "      <td>initial research</td>\n",
       "      <td>find the wealthiest zip code near you. \\n\\nrestrict your searches to that. \\n\\nwealthy folks take great care of their cars, and when they sell them private ...</td>\n",
       "      <td>Provide data-driven neighborhood quality indicators for used car searches</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nj0hkds/</td>\n",
       "      <td>how do you buy a used car?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buyer</td>\n",
       "      <td>financing</td>\n",
       "      <td>Always get your own financing.  Get pre-approved letter from your bank.  Dont use dealer financing.   Dealer will lie and give you higher intrest rate.</td>\n",
       "      <td>Provide transparent financing options and pre-approval tools</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nizbjeb/</td>\n",
       "      <td>how do you buy a used car?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>buyer</td>\n",
       "      <td>inspection and car condition</td>\n",
       "      <td>Look at oilchange sticker on window.  Is it overdue for oil change?   If its overdue than a major red flag.</td>\n",
       "      <td>Provide maintenance history indicators to buyers</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nizbjeb/</td>\n",
       "      <td>how do you buy a used car?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>buyer</td>\n",
       "      <td>initial research</td>\n",
       "      <td>Then Covid happened and used car prices soared.  I expect that has mostly corrected, but I wonder.</td>\n",
       "      <td>provide updated market pricing info to help buyers assess value</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1mf7v5k/is_buying_a_used_car_still_the_way_to_go/n6f5k2z/</td>\n",
       "      <td>Is buying a used car still the way to go?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>buyer</td>\n",
       "      <td>choosing the right car</td>\n",
       "      <td>The downside to this method is leg work. Also, finding someone to inspect the car for you.</td>\n",
       "      <td>offer inspection services or trusted inspectors to reduce buyer effort and risk</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1mf7v5k/is_buying_a_used_car_still_the_way_to_go/n6fkfk7/</td>\n",
       "      <td>Is buying a used car still the way to go?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>buyer</td>\n",
       "      <td>post purchase</td>\n",
       "      <td>QC is worse than it ever has been in my lifetime with vehicles and if these new, complex engines arent properly maintained they just don't last. Maybe I'm j...</td>\n",
       "      <td>provide reliable maintenance history and quality assurance for used cars</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1mf7v5k/is_buying_a_used_car_still_the_way_to_go/n6f23mu/</td>\n",
       "      <td>Is buying a used car still the way to go?</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buyer</td>\n",
       "      <td>scheduling and meeting the other party</td>\n",
       "      <td>They either don't reply, or they do but ghost me after a few messages, or they set up a meeting time then message to say it's sold.</td>\n",
       "      <td>help buyers connect reliably with sellers and reduce ghosting</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1mk5cyg/how_do_people_even_buy_used_cars/</td>\n",
       "      <td>How do people even buy used cars.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>buyer</td>\n",
       "      <td>negotiation and pricing</td>\n",
       "      <td>Be direct, don't ask too many questions online, wait until you see it in person.</td>\n",
       "      <td>guide buyers on effective messaging to sellers to improve response rates</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1mk5cyg/how_do_people_even_buy_used_cars/n7g4v7p/</td>\n",
       "      <td>How do people even buy used cars.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>buyer</td>\n",
       "      <td>initial research</td>\n",
       "      <td>What I've seen is if you're trying to buy a normal 2008 Honda Accord type of car it's a nightmare because everyone is trying to buy the same $5000 car that'...</td>\n",
       "      <td>help buyers find less competitive cars or streamline quick contact with sellers</td>\n",
       "      <td>https://www.reddit.com/r/UsedCars/comments/1mk5cyg/how_do_people_even_buy_used_cars/n7g5wmi/</td>\n",
       "      <td>How do people even buy used cars.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   persona                                   stage  \\\n",
       "0    buyer                        initial research   \n",
       "1    buyer                  choosing the right car   \n",
       "2    buyer            inspection and car condition   \n",
       "3    buyer                        initial research   \n",
       "4    buyer                               financing   \n",
       "5    buyer            inspection and car condition   \n",
       "6    buyer                        initial research   \n",
       "7    buyer                  choosing the right car   \n",
       "8    buyer                           post purchase   \n",
       "9    buyer  scheduling and meeting the other party   \n",
       "10   buyer                 negotiation and pricing   \n",
       "11   buyer                        initial research   \n",
       "\n",
       "                                                                                                                                                     verbatim_quote  \\\n",
       "0   Well, if you\u0019ve never bought one or been to a dealership, do not ever go in person. They\n",
       " see you coming a mile away and get you to buy something you don\u001bt ...   \n",
       "1   Vehicle history is important. Was it a rental? How many owners, any accidents, and how was the maintenance? Most dealerships will offer a car fax history re...   \n",
       "2   If you made it this far and want to take the extra step, especially if you didnt understand all of that. Drive it to a reputable shop across town. Pay for a...   \n",
       "3   find the wealthiest zip code near you. \\n\\nrestrict your searches to that. \\n\\nwealthy folks take great care of their cars, and when they sell them private ...   \n",
       "4           Always get your own financing.  Get pre-approved letter from your bank.  Dont use dealer financing.   Dealer will lie and give you higher intrest rate.   \n",
       "5                                                       Look at oilchange sticker on window.  Is it overdue for oil change?   If its overdue than a major red flag.   \n",
       "6                                                                Then Covid happened and used car prices soared.  I expect that has mostly corrected, but I wonder.   \n",
       "7                                                                        The downside to this method is leg work. Also, finding someone to inspect the car for you.   \n",
       "8   QC is worse than it ever has been in my lifetime with vehicles and if these new, complex engines arent properly maintained they just don't last. Maybe I'm j...   \n",
       "9                               They either don't reply, or they do but ghost me after a few messages, or they set up a meeting time then message to say it's sold.   \n",
       "10                                                                                 Be direct, don't ask too many questions online, wait until you see it in person.   \n",
       "11  What I've seen is if you're trying to buy a normal 2008 Honda Accord type of car it's a nightmare because everyone is trying to buy the same $5000 car that'...   \n",
       "\n",
       "                                                                                       opportunity  \\\n",
       "0   Provide trustworthy third party tools to handle dealer interactions and avoid pressure tactics   \n",
       "1        Offer comprehensive vehicle history and condition reports; facilitate trusted inspections   \n",
       "2                 Provide easy access to trusted inspection services and clear condition summaries   \n",
       "3                        Provide data-driven neighborhood quality indicators for used car searches   \n",
       "4                                     Provide transparent financing options and pre-approval tools   \n",
       "5                                                 Provide maintenance history indicators to buyers   \n",
       "6                                  provide updated market pricing info to help buyers assess value   \n",
       "7                  offer inspection services or trusted inspectors to reduce buyer effort and risk   \n",
       "8                         provide reliable maintenance history and quality assurance for used cars   \n",
       "9                                    help buyers connect reliably with sellers and reduce ghosting   \n",
       "10                        guide buyers on effective messaging to sellers to improve response rates   \n",
       "11                 help buyers find less competitive cars or streamline quick contact with sellers   \n",
       "\n",
       "                                                                                               permalink  \\\n",
       "0                  https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nj4df06/   \n",
       "1                  https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nizb6pt/   \n",
       "2                  https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nizb6pt/   \n",
       "3                  https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nj0hkds/   \n",
       "4                  https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nizbjeb/   \n",
       "5                  https://www.reddit.com/r/UsedCars/comments/1o426it/how_do_you_buy_a_used_car/nizbjeb/   \n",
       "6   https://www.reddit.com/r/UsedCars/comments/1mf7v5k/is_buying_a_used_car_still_the_way_to_go/n6f5k2z/   \n",
       "7   https://www.reddit.com/r/UsedCars/comments/1mf7v5k/is_buying_a_used_car_still_the_way_to_go/n6fkfk7/   \n",
       "8   https://www.reddit.com/r/UsedCars/comments/1mf7v5k/is_buying_a_used_car_still_the_way_to_go/n6f23mu/   \n",
       "9                   https://www.reddit.com/r/UsedCars/comments/1mk5cyg/how_do_people_even_buy_used_cars/   \n",
       "10          https://www.reddit.com/r/UsedCars/comments/1mk5cyg/how_do_people_even_buy_used_cars/n7g4v7p/   \n",
       "11          https://www.reddit.com/r/UsedCars/comments/1mk5cyg/how_do_people_even_buy_used_cars/n7g5wmi/   \n",
       "\n",
       "                                 thread_title location_city location_state  \n",
       "0                  how do you buy a used car?          None           None  \n",
       "1                  how do you buy a used car?          None           None  \n",
       "2                  how do you buy a used car?          None           None  \n",
       "3                  how do you buy a used car?          None           None  \n",
       "4                  how do you buy a used car?          None           None  \n",
       "5                  how do you buy a used car?          None           None  \n",
       "6   Is buying a used car still the way to go?          None           None  \n",
       "7   Is buying a used car still the way to go?          None           None  \n",
       "8   Is buying a used car still the way to go?          None           None  \n",
       "9           How do people even buy used cars.          None           None  \n",
       "10          How do people even buy used cars.          None           None  \n",
       "11          How do people even buy used cars.          None           None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No manual drops; rows: 160\n"
     ]
    }
   ],
   "source": [
    "# --- Stage 5: Review (summary + preview) ---\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 160)\n",
    "\n",
    "df = pd.DataFrame(filtered)\n",
    "\n",
    "# 1) High-level summary: counts by persona / stage / source\n",
    "summary = (\n",
    "    df.groupby([\"persona\", \"stage\", \"source_type\"], dropna=False)\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    "      .sort_values([\"persona\",\"stage\",\"count\"], ascending=[True, True, False])\n",
    ")\n",
    "display(summary.head(30))\n",
    "\n",
    "# 2) Distribution by stage (quick sanity)\n",
    "stage_counts = df[\"stage\"].value_counts().rename_axis(\"stage\").reset_index(name=\"count\")\n",
    "display(stage_counts)\n",
    "\n",
    "# 3) Human-friendly preview of the first N rows\n",
    "preview_cols = [\n",
    "    \"persona\",\"stage\",\"verbatim_quote\",\"opportunity\",\n",
    "    \"permalink\",\"thread_title\",\"location_city\",\"location_state\"\n",
    "]\n",
    "preview = df[preview_cols].head(12)\n",
    "display(preview)\n",
    "\n",
    "\n",
    "# 4) (Optional) mark-and-drop any rows by index before saving\n",
    "#    After you scan `preview` or `df`, put indices to drop here:\n",
    "drop_idx = []   # e.g., [3, 7]\n",
    "if drop_idx:\n",
    "    df = df.drop(index=drop_idx).reset_index(drop=True)\n",
    "    print(f\"Dropped {len(drop_idx)} rows; remaining: {len(df)}\")\n",
    "else:\n",
    "    print(f\"No manual drops; rows: {len(df)}\")\n",
    "\n",
    "# Keep `df` as the reviewed set for Stage 6 save.\n",
    "reviewed_rows = df.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1ec48dc-24f2-4b3a-8153-1148fe7b8d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Insights saved → ../data/exports/insights_20251025_1652.md\n",
      "\n",
      "--- Preview (first 60 lines) ---\n",
      "# Private-Party Used-Car Transactions: UX Research Report\n",
      "\n",
      "---\n",
      "\n",
      "## 0) Scope & Method\n",
      "\n",
      "- **Research window:** Last 24 months (2023-11-05 to 2025-10-25 UTC)  \n",
      "- **Sources:** Reddit; subreddits UsedCars, MechanicAdvice, WhatCarShouldIBuy, cars, Scams, AskCarsales  \n",
      "- **Sample size:** 160 coded rows from 80 threads (max top 4 comments per thread)  \n",
      "\n",
      "---\n",
      "\n",
      "## 1) Executive Summary\n",
      "\n",
      "- **Inspection & condition** is the most frequent pain point for buyers, with distrust of sellers and dealers refusing independent inspections.  \n",
      "- **Paperwork** complexity and title transfer issues cause significant anxiety and risk, especially with liens and multi-party transactions.  \n",
      "- **Payment** stage involves high risk of scams, unclear payment guarantees, and challenges coordinating secure fund/title exchange.  \n",
      "- **Financing private-party sales** is poorly understood, with limited options and lack of clear guidance compared to dealership financing.  \n",
      "- **Negotiation & pricing** uncertainty leads to buyer hesitation; lack of transparent market data complicates fair price assessment.  \n",
      "- **Scheduling & meeting** challenges include ghosting sellers, slow responses, and unsafe or unusual meeting locations.  \n",
      "- Buyers rely on **workarounds** like third-party inspections, OBD-II scans, and community advice but face limits in trust and cost.  \n",
      "- Competitors like **Carfax, KeySavvy, Copilot, Autotrader PSE, and escrow services** address some pain points but gaps remain in inspection, financing, and secure payment flows.  \n",
      "\n",
      "---\n",
      "\n",
      "## 2) Trends by Stage\n",
      "\n",
      "### Initial Research  \n",
      "- **Pain:** Difficulty verifying seller authenticity and spotting scams.  \n",
      "- **Persona:** Buyer  \n",
      "- **Quote:** \"The listing was only posted the same day... timing doesn’t add up.\" (Initial research)  \n",
      "\n",
      "### Choosing the Right Car  \n",
      "- **Pain:** Risk of hidden mechanical issues and unreliable models; high prices for high-mileage cars.  \n",
      "- **Persona:** Buyer  \n",
      "- **Quote:** \"Toyota Camry/Corolla or Honda Civic/Accord can last to 300k with proper care.\" (Choosing the right car)  \n",
      "\n",
      "### Inspection and Car Condition  \n",
      "- **Pain:** Dealers refusing independent inspections; unclear inspection availability and pricing; distrust of seller’s mechanic.  \n",
      "- **Persona:** Buyer  \n",
      "- **Quote:** \"No one wants me to have their cars inspected before buying.\" (Inspection and car condition)  \n",
      "\n",
      "### Financing  \n",
      "- **Pain:** Lack of clear info on financing private sales; credit unions limited to draft payments; higher costs and headaches.  \n",
      "- **Persona:** Buyer  \n",
      "- **Quote:** \"How different is financing a car for a private sale?\" (Financing)  \n",
      "\n",
      "### Negotiation and Pricing  \n",
      "- **Pain:** Uncertainty about fair price; inefficient communication; fear of overpaying or buying lemons.  \n",
      "- **Persona:** Buyer  \n",
      "- **Quote:** \"Is $4k fair for this Rogue with AC+inspection included?\" (Negotiation and pricing)  \n",
      "\n",
      "### Scheduling and Meeting  \n",
      "- **Pain:** Seller ghosting; slow responses; unsafe meeting locations like currency exchanges or banks.  \n",
      "- **Persona:** Buyer  \n",
      "- **Quote:** \"They either don't reply, or ghost me after a few messages.\" (Scheduling and meeting)  \n",
      "\n",
      "### Paperwork  \n",
      "- **Pain:** Complex title transfers, especially with liens or third-party buyers; risk of fraud or extortion; lack of legal recourse.  \n",
      "- **Persona:** Buyer  \n"
     ]
    }
   ],
   "source": [
    "# --- Stage 6: Insight Summarization (UX-research style) ---\n",
    "\n",
    "import os, json, random, pandas as pd, datetime as dt, glob\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ---- 6A) Build compact aggregates from df (must come BEFORE prompt uses agg_payload) ----\n",
    "def _norm(s):\n",
    "    if pd.isna(s): return None\n",
    "    s = \" \".join(str(s).split())\n",
    "    return s if s else None\n",
    "\n",
    "df_slim = df.copy()\n",
    "for col in [\"pain\",\"workaround\",\"potential_competitor\",\"verbatim_quote\",\"action\",\"feeling\",\"opportunity\"]:\n",
    "    if col in df_slim.columns:\n",
    "        df_slim[col] = df_slim[col].apply(_norm)\n",
    "\n",
    "by_ps = (df_slim.groupby([\"persona\",\"stage\"], dropna=False)\n",
    "         .size().reset_index(name=\"count\")\n",
    "         .sort_values(\"count\", ascending=False))\n",
    "\n",
    "top_pains = (df_slim[\"pain\"].dropna().str.strip().str.lower()\n",
    "             .value_counts().head(15).reset_index())\n",
    "top_pains.columns = [\"pain\", \"count\"]\n",
    "\n",
    "top_workarounds = (df_slim[\"workaround\"].dropna().str.strip()\n",
    "                   .value_counts().head(15).reset_index())\n",
    "top_workarounds.columns = [\"workaround\",\"count\"]\n",
    "\n",
    "competitors = (df_slim[\"potential_competitor\"].dropna().str.strip()\n",
    "               .value_counts().head(15).reset_index())\n",
    "competitors.columns = [\"competitor\",\"mentions\"]\n",
    "\n",
    "def sample_rows(n=60):\n",
    "    pool = df_slim.dropna(subset=[\"verbatim_quote\"])\n",
    "    if len(pool) <= n: \n",
    "        return pool\n",
    "    out, per_stage = [], max(1, n // max(1, pool[\"stage\"].nunique()))\n",
    "    for stage, g in pool.groupby(\"stage\"):\n",
    "        out.append(g.sample(min(per_stage, len(g)), random_state=42))\n",
    "    return pd.concat(out).head(n)\n",
    "\n",
    "sample = sample_rows(60)\n",
    "\n",
    "def to_records_table(frame, cols):\n",
    "    def trunc(s, n=280):\n",
    "        s = str(s);  return (s[:n] + \"…\") if len(s) > n else s\n",
    "    return [{c: trunc(row.get(c, \"\")) for c in cols}\n",
    "            for row in frame[cols].to_dict(orient=\"records\")]\n",
    "\n",
    "agg_payload = {\n",
    "    \"counts_by_persona_stage\": by_ps.to_dict(orient=\"records\"),\n",
    "    \"top_pains\": top_pains.to_dict(orient=\"records\"),\n",
    "    \"top_workarounds\": top_workarounds.to_dict(orient=\"records\"),\n",
    "    \"competitors\": competitors.to_dict(orient=\"records\"),\n",
    "    \"sample_rows\": to_records_table(\n",
    "        sample,\n",
    "        [\"persona\",\"stage\",\"pain\",\"workaround\",\"potential_competitor\",\"verbatim_quote\",\"opportunity\",\"permalink\",\"thread_title\"]\n",
    "    )\n",
    "}\n",
    "\n",
    "# ---- 6B) Build scope/method strings (after aggregates, so df exists) ----\n",
    "today = dt.datetime.utcnow().date()\n",
    "try:\n",
    "    RECENCY_MONTHS\n",
    "except NameError:\n",
    "    RECENCY_MONTHS = max(1, int(SINCE_DAYS // 30))\n",
    "start_date = today - dt.timedelta(days=RECENCY_MONTHS * 30)\n",
    "research_window_str = f\"last {RECENCY_MONTHS} months ({start_date.isoformat()} to {today.isoformat()} UTC)\"\n",
    "\n",
    "# prefer bundles_dedup, else count cached files, else len(df)\n",
    "try:\n",
    "    thread_count = len(bundles_dedup)\n",
    "except NameError:\n",
    "    raw_dir = EXPORTS / f\"raw_{RUN_ID}\"\n",
    "    thread_count = len(list((raw_dir).glob(\"*.json\"))) if raw_dir.exists() else None\n",
    "if not thread_count:\n",
    "    thread_count = None\n",
    "sample_counts_str = f\"{len(df)} coded rows\" + (f\" from {thread_count} threads\" if thread_count else \"\") + f\" (top {TOP_COMMENTS} comments per thread max)\"\n",
    "\n",
    "sources_str = f\"Reddit; subreddits: {', '.join(SUBREDDITS)}\"\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You are a senior UX researcher. Analyze private-party used-car transactions \"\n",
    "    \"(buyer and seller dealing directly, not dealers). Find pain points, patterns, and opportunities. \"\n",
    "    \"Be concise, evidence-backed, and pragmatic.\"\n",
    ")\n",
    "\n",
    "USER = f\"\"\"\n",
    "You are given aggregated stats and a sample of rows (each with persona, stage, pain, workaround,\n",
    "competitor mention, and a verbatim quote). Produce a structured MARKDOWN report with:\n",
    "\n",
    "0) **Scope & Method** — Explicitly state:\n",
    "   • Research window: {research_window_str}\n",
    "   • Sources: {sources_str}\n",
    "   • Sample size: {sample_counts_str}\n",
    "\n",
    "1) Executive summary (5–8 bullets).\n",
    "2) Trends by stage (major pain points; which persona; include a short supporting quote ≤120 chars; cite stage).\n",
    "3) Workarounds & their limits (what users try; risks; where experience breaks).\n",
    "4) Competitors/solutions mentioned (what they solve vs. gaps; call out named products/services).\n",
    "5) Opportunities (specific, testable product ideas for concierge/financing/inspection/payment flows).\n",
    "6) Risks/unknowns (what needs validation in interviews).\n",
    "\n",
    "Rules:\n",
    "- Use concise bullet lists. Do NOT invent facts.\n",
    "- Quotes must be verbatim snippets from provided data (short).\n",
    "- Prefer patterns supported by multiple rows.\n",
    "\n",
    "DATA (JSON):\n",
    "{json.dumps(agg_payload, ensure_ascii=False)}\n",
    "\"\"\"\n",
    "\n",
    "# ---- 6C) Call the model (Responses API is fine for markdown output) ----\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",   # or \"o3-mini\"\n",
    "    temperature=0.2,\n",
    "    input=[\n",
    "        {\"role\":\"system\",\"content\": SYSTEM},\n",
    "        {\"role\":\"user\",\"content\": USER}\n",
    "    ]\n",
    ")\n",
    "\n",
    "insights_md = resp.output_text\n",
    "\n",
    "# Save and preview\n",
    "out_md = EXPORTS / f\"insights_{RUN_ID}.md\"\n",
    "with open(out_md, \"w\") as f:\n",
    "    f.write(insights_md)\n",
    "\n",
    "print(\"✅ Insights saved →\", out_md)\n",
    "print(\"\\n--- Preview (first 60 lines) ---\")\n",
    "print(\"\\n\".join(insights_md.splitlines()[:60]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56533018-4c79-4937-8dad-2f58099267dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage 7: Google Sheets writer (new tab per run) ---\n",
    "\n",
    "import os, math, datetime as dt, pandas as pd, gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "\n",
    "SHEET_ID = os.getenv(\"GOOGLE_SHEETS_SPREADSHEET_ID\")\n",
    "assert SHEET_ID, \"Missing GOOGLE_SHEETS_SPREADSHEET_ID in .env\"\n",
    "\n",
    "# resolve creds path from env, tolerate running inside notebooks/\n",
    "raw_key_path = os.getenv(\"GOOGLE_CREDENTIALS_PATH\", \"google-credentials.json\")\n",
    "key_path = Path(raw_key_path).expanduser()\n",
    "if not key_path.exists():\n",
    "    key_path = Path(\"..\") / raw_key_path\n",
    "assert key_path.exists(), f\"Credentials file not found at '{raw_key_path}' or '{key_path}'\"\n",
    "\n",
    "# auth\n",
    "creds = Credentials.from_service_account_file(\n",
    "    str(key_path), scopes=[\"https://www.googleapis.com/auth/spreadsheets\"]\n",
    ")\n",
    "gc = gspread.authorize(creds)\n",
    "ss = gc.open_by_key(SHEET_ID)\n",
    "\n",
    "# make a deterministic tab name\n",
    "tab_name = dt.datetime.utcnow().strftime(f\"run_{RUN_ID}\")\n",
    "\n",
    "# create worksheet (if name already exists, add a suffix)\n",
    "try:\n",
    "    ws = ss.add_worksheet(title=tab_name, rows=2000, cols=30)\n",
    "except gspread.exceptions.APIError:\n",
    "    ws = ss.add_worksheet(title=tab_name + \"_1\", rows=2000, cols=30)\n",
    "\n",
    "# turn reviewed_rows into a DataFrame (ensures column order)\n",
    "df = pd.DataFrame(reviewed_rows)\n",
    "\n",
    "# write headers first\n",
    "ws.update([df.columns.tolist()])\n",
    "\n",
    "# write data in chunks (Google API cell size limits)\n",
    "values = df.astype(object).where(pd.notnull(df), None).values.tolist()\n",
    "chunk_size = 500  # rows per chunk; tune as needed\n",
    "for i in range(0, len(values), chunk_size):\n",
    "    ws.append_rows(values[i:i+chunk_size], value_input_option=\"RAW\")\n",
    "\n",
    "print(f\"✅ Wrote {len(df)} rows to sheet '{ss.title}' tab '{ws.title}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2394934c-52bc-490c-a13d-61844940e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK → User Journey Mapping | using key: ../google-credentials.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536b587-ceff-4d9b-ba4b-4a58b9b184bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (journey)",
   "language": "python",
   "name": "journey"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
